Energy hackathon.



All methods:

    Instead of predicting diurnal cycle directly, why not remove the daily mean value from that day, and for temperature and irradiance, remove either the {mean [diurnal cycle minus daily mean]} or the {mean [(diurnal cycle minus daily mean) scaled by the daily range (max-min)]}, and predict the hourly variation from this? As we have that information.

    Use mean solar to do same for net surface short wave: calculate mean diurnal cycle for calendar day, with daily mean 1, and multiply by daily mean
    
    Wind will be harder, and more dependant on weather patterns probably.



Analogue method:

- use pressure pca clustering on TEST DATA (gridded ERA5, daily mean) to define a number of weather patterns (for winter, first)
- for a given date "d" NOT in TEST DATA:
  - identify cluster that this date sits in
  - for all dates in the TEST DATA in this cluster
    - choose the N dates which best match "d", based on the minimisation of some weighted cost function of the best correlated daily variables (sum(p**2 * RMS**2) ? for p = mean pearson correlation coeff between daily variable and target variable over set of 24 hours)
  - use this set of N dates as an "analogue ensemble" to provide a distribution of probable diurnal cycles for given day based on daily mean
Note: use of clusters adds an element of nonlinearity: if we do correlations *within* each cluster, to weight analogue choices
  
  
  
Daily variables:

  Mean over UK:
    y Net surface short wave radiation (W/m2)
      Cloud cover (%)
      Precipitation mm/day
      sea level pressure (hPa), 
    y Max temperature (1.5m)
      Specific humidity (%)
    y Temperature mean (1.5m)
    y Min temperature (1.5m)
      Snow variables
    y wind speed( at 10m in m/s)
      Eastwards windspeed (m/s)
      Northwards Windspeed (m/s)
    
  Principal components of:
    Pressure anomalies
    Wet Bulb Potential Temperature anonalies
    
  Date (/position in season)
  
 
 
To do:

    - 
    - 
    
    
    
Markov chains:

  Predictor/output:
  
    Time of daily max, tmax(d)
    
    In chains going forwards (backwards) from tmax, the temperature difference between tmax+1 (tmax-1) and tmax
    
  Inputs:
  
     The daily variables listed above, both for today, d, and tomorrow d+1 (yesterday d-1)
     Hour of day
     
     
     
     
     
Conclusions:

  - On a national average scale, for the UK, the dirunal cycles can be reproduced very well for surface shortwave and 2m temperature using historical data to construct normalised hourly patterns, and daily mean values for the target period (and daily maxima and minima for temperature).
  - The national averages are largely not dependant on additional meteorological varaibles such as mean cloud cover or pressure patterns.
    - that said, looking at case 2, temperature method can still lead to underprediction of minima: could benefit from overnight cloud cover?
  - I would hypothesise that a sensible way to reproduce national average wind speed would be to sub-divide the nation into a dozen or so regions (chosen such that they will typically experience similar wind velocities), downscale windspeed for each of these regions, using e.g. random forest, with inputs of (principal components of pressure and temperature, cloud, eastward & northward wind velocites (separately), min and max temperatures), and then take national average windspeed to be the mean of these.
  - I would also expect such more sophisticated methods to be more useful for downscaling 2m temperature and surface shortwave on more local scales
  - Whether the use of an analogue ensemble approach is appropriate for this problem will depend on the user's particular needs. It does not seem to be a good choice for the national average, but may be valuable on a grid-point scale.
  - RMSE is perhaps not the most suitable verification metric if we care most about extreme values: a more sensible metric might weight the ability to accurately predict a given value for temperature, wind speed, etc. based on how much the consumer cares about accurately predicting the variable when it takes this value, and choose the error norm (L1, L2, L3 etc) based on how much more they want to punish large errors over small.
    - We must have been using "mean error" as opposed to "mean absolute error", as MAE (L1 norm) should perform very similarly to RMSE (L2 norm), but giving slightly less weight to large discrepencies
    - Presumably the random forest and linear regression methods will have been trained to minimise some function (which is often by default similar to RMSE?). If we use a   different verification metric, this needs to be accounted for in the training.
