{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "#\n",
    "# in this script we will read in some ERA5 data and then country mask it.\n",
    "# For all years from 1979-2020\n",
    "#\n",
    "# This script is a simple starter script, it can be adapted to read in\n",
    "# multiple years of data or to read in different fields. \n",
    "# \n",
    "# Other functions are also available to load the data in the libraries: \n",
    "# - cfpython \n",
    "# - xarray\n",
    "# - iris\n",
    "#\n",
    "#########\n",
    "\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_country_mask(COUNTRY,data_dir,filename,nc_key):\n",
    "\n",
    "    '''\n",
    "\n",
    "    This function loads the country masks for the ERA5 data grid we have been using\n",
    "\n",
    "    Args:\n",
    "        COUNTRY (str): This must be a name of a country (or set of) e.g. \n",
    "            'United Kingdom','France','Czech Republic'\n",
    " \n",
    "       data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "\n",
    "        nc_key (str): The string you need to load the .nc data \n",
    "            e.g. 't2m','rsds'\n",
    "\n",
    "    Returns:\n",
    "       MASK_MATRIX_RESHAPE (array): Dimensions [lat,lon] where there are 1's if \n",
    "           the data is within a country border and zeros if data is outside a \n",
    "           country border. \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    # first loop through the countries and extract the appropraite shapefile\n",
    "    countries_shp = shpreader.natural_earth(resolution='10m',category='cultural',\n",
    "                                            name='admin_0_countries')\n",
    "    country_shapely = []\n",
    "    for country in shpreader.Reader(countries_shp).records():\n",
    "        if country.attributes['NAME_LONG'] == COUNTRY:\n",
    "            print('Found country')\n",
    "            country_shapely.append(country.geometry)\n",
    "\n",
    "    # load in the data you wish to mask\n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r')\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    data = dataset.variables[nc_key][:] # data in shape [time,lat,lon]\n",
    "    \n",
    "    print(data.shape)\n",
    "    dataset.close()\n",
    "\n",
    "    # get data in appropriate units for models\n",
    "    if nc_key == 't2m':\n",
    "        data = data-273.15 # convert to Kelvin from Celsius\n",
    "    if nc_key == 'ssrd':\n",
    "        data = data/3600. # convert Jh-1m-2 to Wm-2\n",
    "\n",
    "    LONS, LATS = np.meshgrid(lons,lats) # make grids of the lat and lon data\n",
    "    x, y = LONS.flatten(), LATS.flatten() # flatten these to make it easier to \n",
    "    #loop over.\n",
    "    points = np.vstack((x,y)).T\n",
    "    MASK_MATRIX = np.zeros((len(x),1))\n",
    "    # loop through all the lat/lon combinations to get the masked points\n",
    "    for i in range(0,len(x)):\n",
    "        my_point = shapely.geometry.Point(x[i],y[i]) \n",
    "        if country_shapely[0].contains(my_point) == True: \n",
    "            MASK_MATRIX[i,0] = 1.0 # creates 1s and 0s where the country is\n",
    "    \n",
    "    MASK_MATRIX_RESHAPE = np.reshape(MASK_MATRIX,(len(lats),len(lons)))\n",
    "\n",
    "\n",
    "    return(MASK_MATRIX_RESHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country_weather_data(MASK_MATRIX_RESHAPE, data_dir,filename,nc_key):\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    This functions takes the ERA5 reanalysis data, loads it and applies a \n",
    "    pre-loaded country mask. It then takes the mean over that country mask\n",
    "    and returns a time series of the data.\n",
    "    \n",
    "    Note tha unit conversions are currently only implemented for nc_keys of 't2m'\n",
    "    and 'ssrd'\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    MASK_MATRIX_RESHAPE (array): Dimensions [lat,lon]. where there are 1s within a \n",
    "        country border and zeros outside it.\n",
    "        \n",
    "    data dir (str): the path for where the data is stored\n",
    "    \n",
    "    filename (str): the filesname of a .netcdf (.nc) file\n",
    "    \n",
    "    nc_key (str) : the string you need to load the .nc file e.g. 't2m' or 'ssrd'\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    filestr = data_dir + filename\n",
    "    dataset = Dataset(filestr,mode='r')\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    data = dataset.variables[nc_key][:]\n",
    "    dataset.close()\n",
    "    \n",
    "    if nc_key == 't2m':\n",
    "        data = data-273.15 # convert from K to degCelsius\n",
    "    if nc_key == 'ssrd':\n",
    "        data = data/3600. #convert Jh-1m-2 to Wm-2\n",
    "        \n",
    "    country_masked_data = np.zeros(np.shape(data))\n",
    "    for i in range(0,len(country_masked_data)):\n",
    "        country_masked_data[i,:,:] = data[i,:,:]*MASK_MATRIX_RESHAPE\n",
    "        \n",
    "    country_masked_data[country_masked_data ==0.] = np.nan\n",
    "    \n",
    "    country_timeseries=np.nanmean(np.nanmean(country_masked_data,axis=2),axis=1)\n",
    "                                 \n",
    "    return(country_timeseries,lats,lons)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variable_data(var):\n",
    "\n",
    "    ''' \n",
    "    This function collects the specified variable data for the UK from 1979-2020 on an hourly basis.\n",
    "    It returns an array of the variables with the dims (# of years, # of hours in a year). This function does\n",
    "    not account for leap-year days (Feb 29).\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "    var (str): the name of the variable in the netCDF to collect (ex: t2m, ssrd, etc) \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    2d-array (array-obj): dims (# of years, 8760)\n",
    "    \n",
    "    '''\n",
    "    ERA5_var_data = np.zeros([2021-1979,8760]) #number of years, number of hours in a standard year\n",
    "\n",
    "    for qyear in range(1979,2021): # loop over the years\n",
    "\n",
    "        aggregate_var = []\n",
    "\n",
    "        print(qyear)\n",
    "        for qmonth in range(1,13): # loop over the months\n",
    "            #print(qmonth)\n",
    "            qmonthchar = str(qmonth).zfill(2)\n",
    "            qyearchar = str(qyear)\n",
    "\n",
    "            file_loc = '/gws/pw/j05/cop26_hackathons/oxford/Data/ERA5_data_EU_domain/field_set_1/'\n",
    "            file_name = 'ERA5_1hr_field_set_1_' + qyearchar + '_' + qmonthchar + '.nc' \n",
    "\n",
    "            var_data,lats,lons =load_country_weather_data(country_mask,file_loc,file_name,var)\n",
    "\n",
    "            aggregate_var.append(var_data)\n",
    "\n",
    "        var_data = np.array([item for sublist in aggregate_var for item in sublist])\n",
    "        ERA5_var_data[qyear-1979,:] = np.array(var_data)\n",
    "        \n",
    "    return ERA5_var_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jaspy/lib/python3.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "# collect all the variables of interest from the ERA5 data\n",
    "ERA5_ssrd_data = load_variable_data(\"ssrd\")\n",
    "ERA5_msl_data = load_variable_data(\"msl\")\n",
    "ERA5_t2m_data = load_variable_data(\"t2m\")\n",
    "ERA5_u10_data = load_variable_data(\"u10\")\n",
    "ERA5_v10_data = load_variable_data(\"v10\")\n",
    "ERA5_u100_data = load_variable_data(\"u100\")\n",
    "ERA5_v100_data = load_variable_data(\"v100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert country data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368184,)\n"
     ]
    }
   ],
   "source": [
    "# flatten ERA5_data array (year, hour) to (hour,)\n",
    "ERA5_t2m_hourly = ERA5_t2m_data.flatten()\n",
    "ERA5_ssrd_hourly = ERA5_ssrd_data.flatten()\n",
    "ERA5_msl_hourly = ERA5_msl_data.flatten()/100\n",
    "\n",
    "# calculate wind speeds & flatten\n",
    "ERA5_w10_data = np.sqrt(ERA5_u10_data**2 + ERA5_v10_data**2)\n",
    "ERA5_w100_data = np.sqrt(ERA5_u100_data**2 + ERA5_v100_data**2)\n",
    "ERA5_w10_hourly = ERA5_w10_data.flatten()\n",
    "ERA5_w100_hourly = ERA5_w100_data.flatten()\n",
    "\n",
    "# generate hourly values for daterange Jan 1, 1979 - Dec 31, 2020\n",
    "hours = pd.date_range(datetime(1979,1,1,0), datetime(2020,12,31,23), freq = \"1H\")\n",
    "\n",
    "# array lengths do not match. Because leap year days are not accounted for. \n",
    "print(hours.shape)\n",
    "print(ERA5_t2m_hourly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ERA5_t2m_hourly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f211db39737d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# lengths match now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERA5_t2m_hourly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERA5_t2m_hours\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ERA5_t2m_hourly' is not defined"
     ]
    }
   ],
   "source": [
    "# remove all Feb 29 days from hourly values\n",
    "ERA5_t2m_hours = hours[hours.strftime(\"%m%d\") != \"0229\"]\n",
    "ERA5_ssrd_hours = hours[hours.strftime(\"%m%d\") != \"0229\"]\n",
    "ERA5_msl_hours = hours[hours.strftime(\"%m%d\") != \"0229\"]\n",
    "ERA5_w10_hours = hours[hours.strftime(\"%m%d\") != \"0229\"]\n",
    "ERA5_w100_hours = hours[hours.strftime(\"%m%d\") != \"0229\"]\n",
    "\n",
    "# lengths match now\n",
    "print(ERA5_t2m_hourly.shape)\n",
    "print(ERA5_t2m_hours.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in monthly NAO values from NCDC.NOAA\n",
    "nao_monthly = pd.read_csv(\"https://www.ncdc.noaa.gov/teleconnections/nao/data.csv\",header=1)\n",
    "nao_monthly.Date = pd.to_datetime(nao_monthly.Date,format=\"%Y%m\")\n",
    "\n",
    "# select time range 1979-2020\n",
    "nao_monthly = nao_monthly[(nao_monthly.Date>=datetime(1979,1,1,0)) & (nao_monthly.Date<=datetime(2021,1,1,0))]\n",
    "\n",
    "# convert monthly timescale to hourly timescale using repeated values\n",
    "nao_hourly = nao_monthly.set_index(\"Date\").resample(\"1H\").pad()\n",
    "\n",
    "# remove Feb 29th and Jan 1, 2021\n",
    "hourly_nao_value = nao_hourly[nao_hourly.index.strftime(\"%m%d\") != \"0229\"][:-1].Value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pandas dataframe and produce CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({\"t2m\":ERA5_t2m_hourly, \"ssrd\":ERA5_ssrd_hourly, \"msl\":ERA5_msl_hourly,\"w10\":ERA5_w10_hourly,\n",
    "                   \"w100\":ERA5_w100_hourly,\"nao\":hourly_nao_value})\n",
    "df.index = ERA5_t2m_hours\n",
    "\n",
    "# produce CSV\n",
    "df.to_csv(\"country_data/ERA5_t2m_hourly_UK.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
