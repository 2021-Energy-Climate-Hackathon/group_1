{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry\n",
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_time(hours, start_year = 1900):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function calculates the week number, year and hour of the day based on the hours that are stored as 'time' in the ERA dataset.\n",
    "    \n",
    "    Args:\n",
    "        hours: the 'time' variable of the ERA5 dataset\n",
    "        \n",
    "    Returns:\n",
    "        hour: Hour between 0 and 23, 0 presumable corresponds to midnight\n",
    "        week: Week number based on the Gregorian calendar\n",
    "        year: Year number based on the Gregorian calendar\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    start_date = datetime.date(start_year, 1, 1)\n",
    "    hour, week, year = [], [], []\n",
    "    \n",
    "    for hr in hours:\n",
    "        \n",
    "        hours_added = datetime.timedelta(hours = np.int(hr))\n",
    "        date = start_date + hours_added\n",
    "        hour.append(hr%24)\n",
    "        week.append(date.isocalendar()[1])\n",
    "        year.append(date.isocalendar()[0])\n",
    "        \n",
    "    return(hour, week, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country_mask(COUNTRY, data_dir, filename):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    This function loads the country masks for the ERA5 data grid we have been using\n",
    "\n",
    "    Args:\n",
    "        COUNTRY (str): This must be a name of a country (or set of) e.g. \n",
    "            'United Kingdom','France','Czech Republic'\n",
    " \n",
    "       data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "\n",
    "        nc_key (str): The string you need to load the .nc data \n",
    "            e.g. 't2m','rsds'\n",
    "\n",
    "    Returns:\n",
    "       MASK_MATRIX_RESHAPE (array): Dimensions [lat,lon] where there are 1's if \n",
    "           the data is within a country border and zeros if data is outside a \n",
    "           country border. \n",
    "           \n",
    "    '''\n",
    "\n",
    "    # first loop through the countries and extract the appropraite shapefile\n",
    "    countries_shp = shpreader.natural_earth(resolution='10m',category='cultural',\n",
    "                                            name='admin_0_countries')\n",
    "    country_shapely = []\n",
    "    for country in shpreader.Reader(countries_shp).records():\n",
    "        if country.attributes['NAME_LONG'] == COUNTRY:\n",
    "            print('Found country')\n",
    "            country_shapely.append(country.geometry)\n",
    "            \n",
    "    # load in the data you wish to mask\n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r')\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    dataset.close()\n",
    "\n",
    "    LONS, LATS = np.meshgrid(lons,lats) # make grids of the lat and lon data\n",
    "    x, y = LONS.flatten(), LATS.flatten() # flatten these to make it easier to \n",
    "    #loop over.\n",
    "    points = np.vstack((x,y)).T\n",
    "    MASK_MATRIX = np.zeros((len(x),1))\n",
    "    # loop through all the lat/lon combinations to get the masked points\n",
    "    for i in range(0,len(x)):\n",
    "        my_point = shapely.geometry.Point(x[i],y[i]) \n",
    "        if country_shapely[0].contains(my_point) == True: \n",
    "            MASK_MATRIX[i,0] = 1.0 # creates 1s and 0s where the country is\n",
    "    \n",
    "    MASK_MATRIX_RESHAPE = np.reshape(MASK_MATRIX,(len(lats),len(lons)))\n",
    "    return(MASK_MATRIX_RESHAPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_1d_data(data_dir, filename, nc_key):\n",
    "\n",
    "    '''\n",
    "    Args:\n",
    " \n",
    "       data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "\n",
    "        nc_key (str): The string you need to load the .nc data \n",
    "            e.g. 't2m','rsds'\n",
    "\n",
    "    Returns:\n",
    "       data: dimensions [time, lat, lon]\n",
    "\n",
    "        latitudes (array): array of latitudes\n",
    "\n",
    "        longitudes (array): array of longitudes\n",
    "    '''\n",
    "\n",
    "    # load in the variable you want to extract\n",
    "\n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r')\n",
    "\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    data = dataset.variables[nc_key][:] # data in shape [time,lat,lon]\n",
    "    dataset.close()\n",
    "\n",
    "    # get data in appropriate units for models\n",
    "    if nc_key == 't2m':\n",
    "        data = data-273.15 # convert to Kelvin from Celsius\n",
    "    if nc_key == 'ssrd':\n",
    "        data = data/3600. # convert Jh-1m-2 to Wm-2\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_daily_national_data(data_dir, filename, country_mask, input_var, output_var):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "            \n",
    "        country_mask\n",
    "        \n",
    "        input_var: LIST of variables you want as inputs. Make sure they ar present in the dataset you are sending to the function\n",
    "        \n",
    "        output_var: single string of the output variable of interest. Options are t2m, wind10, wind100 (wind is calculated below from u and v)\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "        You have the choice to either compute just the input df, just the output df or both\n",
    "        by commenting/ uncommenting accordingly\n",
    "        Dataframe X (input) with time series of averaged over daily values\n",
    "        Dataframe Y (output) with the hourly values stored in columns\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r') \n",
    "    columns = dataset.variables.keys()\n",
    "    dataset.close()\n",
    "    \n",
    "    columns =  input_var# list of input variables you are interested in processing\n",
    "    out_var = output_var # output variable that you are interested in ---> Set1 only\n",
    "    \n",
    "    df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for col in columns: \n",
    "        \n",
    "        data =  load_1d_data(data_dir, filename, col)\n",
    "    \n",
    "        # country mask the data\n",
    "        country_masked_data = np.zeros(np.shape(data))\n",
    "        for i in range(0,len(country_masked_data)):\n",
    "            country_masked_data[i,:,:] = data[i,:,:]*country_mask\n",
    "\n",
    "        # to make this a national timeseries average over the existing country points, replace 0 with nans\n",
    "        country_masked_data[country_masked_data == 0.] = np.nan\n",
    "\n",
    "        # spatially average\n",
    "        country_timeseries = np.nanmean(np.nanmean(country_masked_data,axis=2),axis=1)\n",
    "        \n",
    "        df[col] = country_timeseries\n",
    "               \n",
    "    '''\n",
    "    Uncomment the next 4 lines only if you want to convert the time column into \n",
    "        weeks number and year and include in your dataset\n",
    "    ''' \n",
    "    \n",
    "    #hours_total = load_1d_data(data_dir, filename, 'time')\n",
    "    #hour, week, year = calc_time(hours_total)\n",
    "    #df['week'] = week\n",
    "    #df['year'] = year\n",
    "    \n",
    "    '''\n",
    "    Uncomment the next 2 lines only if you want to convert u,v to wind speed magnitude\n",
    "    \n",
    "    ---> Set 1 only\n",
    "    '''\n",
    "    \n",
    "    # df['wind10'] = np.sqrt(df['u10']**2 + df['v10']**2)\n",
    "    # df['wind100'] = np.sqrt(df['u100']**2 + df['v100']**2)\n",
    "    \n",
    "    '''\n",
    "    Input features are averaged to get daily values\n",
    "    '''\n",
    "    X = df.groupby(np.arange(len(df))//24).mean()\n",
    "\n",
    "    '''\n",
    "    Uncomment the next 4 lines if you also want to compute the output dataframe.\n",
    "    24 output features need to be collected in Y\n",
    "    We store the hourly values of the output variable into rows\n",
    "    Each row is a day\n",
    "    Each column is an hour\n",
    "    \n",
    "    ---> Set1 only\n",
    "    '''\n",
    "\n",
    "    #Y = pd.DataFrame()\n",
    "    #for idx, df in enumerate(np.array_split(df,  24)):\n",
    "    #    Y[idx] = df[out_var].values\n",
    "    # return(X, Y)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input\n",
    "data_dir = '/gws/pw/j05/cop26_hackathons/oxford/Data/ERA5_data_EU_domain/field_set_2/'\n",
    "set_name = 'set_2'\n",
    "inputs = ['tcc', 'tp']\n",
    "output = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found country\n"
     ]
    }
   ],
   "source": [
    "# filename is only used for the country mask, so doesn't matter which year/ lat/ lon\n",
    "filename = 'ERA5_1hr_field_%s_2000_01.nc'%set_name\n",
    "country_mask = load_country_mask('United Kingdom', data_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jaspy/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# WARNING: takes a long time to compute.\n",
    "\n",
    "years = np.arange(1980, 2001, 1)\n",
    "X = pd.DataFrame()\n",
    "Y = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    print(year) # to see the progres of the loop\n",
    "    for month in np.arange(1, 13, 1):\n",
    "        if X.empty and Y.empty:\n",
    "        #if X.empty:\n",
    "            X, Y = load_daily_national_data(data_dir,'ERA5_1hr_field_%s_%d_%02d.nc'%(set_name, year, month), country_mask)\n",
    "            #X = load_daily_national_data(data_dir,'ERA5_1hr_field_set_2_%d_%02d.nc'%(year, month), country_mask)\n",
    "        else:\n",
    "            df1, df2 = load_daily_national_data(data_dir,'ERA5_1hr_field_%s_%d_%02d.nc'%(set_name, year, month), country_mask)\n",
    "            #df1 = load_daily_national_data(data_dir,'ERA5_1hr_field_set_2_%d_%02d.nc'%(year, month), country_mask)\n",
    "            X = X.append(df1, ignore_index = True)\n",
    "            Y = Y.append(df2, ignore_index = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nsave the dataframes to a file \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "save the dataframes to a file \n",
    "'''\n",
    "\n",
    "#X.to_csv('_set2.dat')\n",
    "#Y.to_csv('_wind10.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to add the nao data from https://www.ncdc.noaa.gov/teleconnections/nao/ but it is monthly.\n",
    "# need to find a way to correctly repeat the rows to have daily values. \n",
    "# probably need to hardcode the number of days each month ? check the python datetime module\n",
    "\n",
    "filename = 'nao.csv'\n",
    "df_nao = pd.read_csv(filename, header = 1, index_col = None)\n",
    "df_nao = df_nao.astype(str)\n",
    "\n",
    "df_nao['year'] = df_nao['Date'].str[:4]\n",
    "df_nao['month'] = df_nao['Date'].str[4:]\n",
    "df_nao.drop(columns = ['Date'], inplace = True)\n",
    "df_nao = df_nao.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nao = df_nao.loc[df_nao['year'].isin(np.arange(1980, 2021))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
