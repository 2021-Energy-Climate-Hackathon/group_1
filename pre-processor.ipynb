{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry\n",
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_time(hours):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function calculates the week number, year and hour of the day based on the hours that are stored as 'time' in the ERA dataset.\n",
    "    \n",
    "    Args:\n",
    "        hours: the 'time' variable of the ERA5 dataset\n",
    "        \n",
    "    Returns:\n",
    "        hour: Hour between 0 and 23, 0 presumable corresponds to midnight\n",
    "        week: Week number based on the Gregorian calendar\n",
    "        year: Year number based on the Gregorian calendar\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    start_date = datetime.date(1900, 1, 1)\n",
    "    hour, week, year = [], [], []\n",
    "    \n",
    "    for hr in hours:\n",
    "        \n",
    "        hours_added = datetime.timedelta(hours = np.int(hr))\n",
    "        date = start_date + hours_added\n",
    "        hour.append(hr%24)\n",
    "        week.append(date.isocalendar()[1])\n",
    "        year.append(date.isocalendar()[0])\n",
    "        \n",
    "    return(hour, week, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country_mask(COUNTRY, data_dir, filename):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    This function loads the country masks for the ERA5 data grid we have been using\n",
    "\n",
    "    Args:\n",
    "        COUNTRY (str): This must be a name of a country (or set of) e.g. \n",
    "            'United Kingdom','France','Czech Republic'\n",
    " \n",
    "       data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "\n",
    "        nc_key (str): The string you need to load the .nc data \n",
    "            e.g. 't2m','rsds'\n",
    "\n",
    "    Returns:\n",
    "       MASK_MATRIX_RESHAPE (array): Dimensions [lat,lon] where there are 1's if \n",
    "           the data is within a country border and zeros if data is outside a \n",
    "           country border. \n",
    "           \n",
    "    '''\n",
    "\n",
    "    # first loop through the countries and extract the appropraite shapefile\n",
    "    countries_shp = shpreader.natural_earth(resolution='10m',category='cultural',\n",
    "                                            name='admin_0_countries')\n",
    "    country_shapely = []\n",
    "    for country in shpreader.Reader(countries_shp).records():\n",
    "        if country.attributes['NAME_LONG'] == COUNTRY:\n",
    "            print('Found country')\n",
    "            country_shapely.append(country.geometry)\n",
    "            \n",
    "    # load in the data you wish to mask\n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r')\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    dataset.close()\n",
    "\n",
    "    LONS, LATS = np.meshgrid(lons,lats) # make grids of the lat and lon data\n",
    "    x, y = LONS.flatten(), LATS.flatten() # flatten these to make it easier to \n",
    "    #loop over.\n",
    "    points = np.vstack((x,y)).T\n",
    "    MASK_MATRIX = np.zeros((len(x),1))\n",
    "    # loop through all the lat/lon combinations to get the masked points\n",
    "    for i in range(0,len(x)):\n",
    "        my_point = shapely.geometry.Point(x[i],y[i]) \n",
    "        if country_shapely[0].contains(my_point) == True: \n",
    "            MASK_MATRIX[i,0] = 1.0 # creates 1s and 0s where the country is\n",
    "    \n",
    "    MASK_MATRIX_RESHAPE = np.reshape(MASK_MATRIX,(len(lats),len(lons)))\n",
    "    return(MASK_MATRIX_RESHAPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_1d_data(data_dir, filename, nc_key):\n",
    "\n",
    "    '''\n",
    "    Args:\n",
    " \n",
    "       data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "\n",
    "        nc_key (str): The string you need to load the .nc data \n",
    "            e.g. 't2m','rsds'\n",
    "\n",
    "    Returns:\n",
    "       data: dimensions [time, lat, lon]\n",
    "\n",
    "        latitudes (array): array of latitudes\n",
    "\n",
    "        longitudes (array): array of longitudes\n",
    "    '''\n",
    "\n",
    "    # load in the variable you want to extract\n",
    "\n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r')\n",
    "\n",
    "    lons = dataset.variables['longitude'][:]\n",
    "    lats = dataset.variables['latitude'][:]\n",
    "    data = dataset.variables[nc_key][:] # data in shape [time,lat,lon]\n",
    "    dataset.close()\n",
    "\n",
    "    # get data in appropriate units for models\n",
    "    if nc_key == 't2m':\n",
    "        data = data-273.15 # convert to Kelvin from Celsius\n",
    "    if nc_key == 'ssrd':\n",
    "        data = data/3600. # convert Jh-1m-2 to Wm-2\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_daily_national_data(data_dir, filename, country_mask):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_dir (str): The parth for where the data is stored.\n",
    "            e.g '/home/users/zd907959/'\n",
    "\n",
    "        filename (str): The filename of a .netcdf file\n",
    "            e.g. 'ERA5_1979_01.nc'\n",
    "            \n",
    "        variable u: u10 or u100\n",
    "        \n",
    "        variable v: v10 or v100\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        Dataframe with time series \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    file_str = data_dir + filename\n",
    "    dataset = Dataset(file_str,mode='r') \n",
    "    columns = dataset.variables.keys()\n",
    "    dataset.close()\n",
    "    \n",
    "    independent_vars = ['time', 'latitude', 'longitude']\n",
    "    columns = [i for i in columns if i not in independent_vars]\n",
    "            \n",
    "    df = pd.DataFrame(columns = columns)\n",
    " \n",
    "\n",
    "    for col in columns: \n",
    "        \n",
    "        data =  load_1d_data(data_dir, filename, col)\n",
    "    \n",
    "        # country mask the data\n",
    "        country_masked_data = np.zeros(np.shape(data))\n",
    "        for i in range(0,len(country_masked_data)):\n",
    "            country_masked_data[i,:,:] = data[i,:,:]*country_mask\n",
    "\n",
    "        # to make this a national timeseries average over the existing country points, replace 0 with nans\n",
    "        country_masked_data[country_masked_data == 0.] = np.nan\n",
    "\n",
    "        # spatially average\n",
    "        country_timeseries = np.nanmean(np.nanmean(country_masked_data,axis=2),axis=1)\n",
    "        \n",
    "        df[col] = country_timeseries\n",
    "                \n",
    "    hours_total = load_1d_data(data_dir, filename, 'time')\n",
    "    hour, week, year = calc_time(hours_total)\n",
    "    \n",
    "    #df['hour'] = hour\n",
    "    df['week'] = week\n",
    "    df['year'] = year\n",
    "    df['wind10'] = np.sqrt(df['u10']**2 + df['v10']**2)\n",
    "    df['wind100'] = np.sqrt(df['u100']**2 + df['v100']**2)\n",
    "\n",
    "    X = df.groupby(np.arange(len(df))//24).mean()\n",
    "\n",
    "    Y = pd.DataFrame()\n",
    "    for idx, df_daily in enumerate(np.array_split(df,  24)):\n",
    "        Y[idx] = df_daily['t2m'].values\n",
    "    return(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found country\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/gws/pw/j05/cop26_hackathons/oxford/Data/ERA5_data_EU_domain/field_set_1/'\n",
    "filename = 'ERA5_1hr_field_set_1_2000_01.nc'\n",
    "country_mask = load_country_mask('United Kingdom', data_dir, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jaspy/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# WARNING: takes AGES to compute.\n",
    "\n",
    "years = np.arange(1980, 2001, 1)\n",
    "X = pd.DataFrame()\n",
    "Y = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    for month in np.arange(1, 13, 1):\n",
    "        if X.empty and Y.empty:\n",
    "            X, Y = load_daily_national_data(data_dir,'ERA5_1hr_field_set_1_%d_%02d.nc'%(year, month), country_mask)\n",
    "        else:\n",
    "            df1, df2 = load_daily_national_data(data_dir,'ERA5_1hr_field_set_1_%d_%02d.nc'%(year, month), country_mask)\n",
    "            X = X.append(df1, ignore_index = True)\n",
    "            Y = Y.append(df2, ignore_index = True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X.dat')\n",
    "Y.to_csv('Y.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
